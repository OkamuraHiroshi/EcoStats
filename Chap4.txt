###  4章  線形回帰モデルのさらなる拡張

## 4 - 1 過分散

library(statmod)      # statmodパッケージを読み込み
g_he <- gauss.quad(10,kind="hermite")      # ガウス・エルミート積分の節点と重みの取得
z <- g_he$nodes      # 節点
w <- g_he$weights       # 重み

dpois_normal <- function(x, mean=0, sd=1){
  dens <- Vectorize(function(x) sum(w*exp(z^2)*exp(dpois(x, lambda=exp(z), log=TRUE)+dnorm(z, mean, sd, log=TRUE))))      # ポアソン分布の平均の対数値が正規分布に従うとして，平均の対数値にあたるランダム効果をガウス積分で積分消去したもの
  
  return(log(dens(x)))     # 対数周辺尤度
}

mod <- function(p, x, model="poisson"){    # possion, negative binomial, possion-normalの負の対数尤度を計算するプログラム
  if (model=="poisson"){      # model=="poisson"なら
    lambda <- exp(p)     # ポアソン分布の平均はパラメータを指数変換したもの
    like <- -sum(dpois(x, lambda=lambda, log=TRUE))       # ポアソン分布の負の対数尤度
  }
  if (model=="negbin"){      # model=="negbin"なら
    mu <- exp(p[1])        # 負の二項分布の平均
    d <- exp(p[2])        # 負の二項分布のdispersion parameter
    like <- -sum(dnbinom(x, size=d, mu=mu, log=TRUE))       # 負の二項分布の負の対数尤度
  }
  if (model=="poisnorm"){      # model=="poisnorm"なら
    mu <- p[1]        # 正規分布の平均
    sigma <- exp(p[2])       # 正規分布の標準偏差
    like <- -sum(dpois_normal(x, mean=mu, sd=sigma))     # ポアソン-正規分布の負の対数尤度
  }
  
  like       # 結果となる負の対数尤度を出力
}

x <- c(1,3,7,0,2,2,0,1,2,8)       # チュパカブラのカウントデータ
mod_1 <- nlm(mod, 0, x=x, model="poisson")        # ポアソン分布モデルのフィット
mod_2 <- nlm(mod, c(0,0), x=x, model="negbin")        # 負の二項分布モデルのフィット
mod_3 <- nlm(mod, c(0,0), x=x, model="poisnorm")        # ポアソン-正規分布モデルのフィット
aic <- function(x) x$minimum*2 + 2*length(x$estimate)        # AICの関数を定義
c("Poisson"=aic(mod_1), "NegBin"=aic(mod_2), "PoisNorm"=aic(mod_3))        # AICの結果を表示

## 4 - 2 ランダム効果モデル

set.seed(1)        # 乱数のseed設定
a <- 0.2      # 直線の切片
b <- -0.3      # 直線の傾き
z <- rnorm(20,0,0.2)        # 切片に付与されるランダム効果
x <- seq(-2,2,by=0.01)       # 固定効果の説明変数
matplot(x,sapply(1:20, function(i) a+z[i]+b*x),type="l",col="blue",lty=1,xlab="x",ylab="log(lambda)")       # ランダム効果を与えて切片を変動させた直線を描画

## 4 - 3 数値的最適化

x <- seq(-5,5,by=0.1)      # xの範囲を設定
plot(x, x^2, xlab="x", ylab="f(x)", type="l", lwd=2, col="blue", xaxt="n", yaxt="n")      # xに対してx^2をプロット

# 勾配降下法
L <- function(x) exp(x)-2*x        # ポアソン分布の対数尤度(x = log(lambda)が推定したいパラメータ）
dL <- function(x) exp(x)-2         # 対数尤度をxで微分したもの
x <- numeric(500)          # xの入れ物
x[1] <- 5        # 初期値をx=5とする
lambda <- 0.01       # 学習率を調整するパラメータ
for (i in 2:500) x[i] <- x[i-1]-lambda*dL(x[i-1])      # 勾配降下法
plot(x,xlab="iteration",ylab="Value",ylim=c(0,5))      # xの値の変化

# Newton-Raphson法
d2L <- function(x) exp(x)       # 2階微分
x <- numeric(20)      # xの入れ物（勾配降下法より収束が速いだろうと想定）
x[1] <- 5       # 初期値をx=5とする
for (i in 2:20) x[i] <- x[i-1]-dL(x[i-1])/d2L(x[i-1])      # Newton-Raphson法
plot(x,xlab="iteration",ylab="x",ylim=c(0,5))      # xの値の変化

f1 <- function(p, x) -sum(dpois(x,lambda=exp(p),log=TRUE))     # ポアソンモデルの対数尤度
f2 <- function(p, x) {     # 勾配を式で与える関数
    res <- f1(p, x)      # ポアソンモデルの対数尤度
    attr(res, "gradient") <- exp(p)-x      # ポアソンモデルの対数尤度の勾配
    res
}
set.seed(1)     # 乱数生成のseed設定
z <- rpois(100, lambda=mean(x))       # 100個のポアソン乱数
system.time(nlm(f1,rep(0,100),x=z))      # 勾配を指定せず準ニュートン法を行う
system.time(nlm(f2,rep(0,100),x=z))      # 勾配を指定してニュートン法を行う

## 4 - 4 ランダム効果の取り扱い

# ラプラス近似による周辺尤度評価のための関数の準備
pn <- function(x, theta, phi) -sum(dpois(x,exp(theta),log=TRUE)+dnorm(theta,phi[1],exp(phi[2]),log=TRUE))      # ポアソン正規モデルの同時対数尤度

g <- function(x, theta, phi) {
  res <- pn(x, theta, phi)      # thetaとphiを与えたときの負の同時対数尤度
  attr(res, "gradient") <- -(x-exp(theta)-(theta-phi[1])/(exp(2*phi[2])))     # phiを与えたときの，負の同時対数尤度のthetaによる微分
  attr(res, "hessian") <- diag(exp(theta)+1/exp(2*phi[2]))        # phiを与えたときの，負の同時対数尤度のヘッセ行列
  res
}

# ラプラス近似による周辺尤度の関数（ランダム効果thetaを積分消去するための内部的最適化を含む）
f <- function(x, phi){
   n <- length(x)        # サンプルサイズ
   theta <- nlm(g, rep(0,n), x=x, phi=phi)$estimate     # phiを与えたときのthetaのMLEを推定
   res <- g(x, theta, phi)       # thetaを与えたときのphiの負の同時対数尤度
   hes <- attr(res, "hessian")     # hessianをhesに入れる
   
   as.numeric(res)-0.5*n*log(2*pi)+0.5*log(det(hes))    # Laplace近似による負の周辺尤度
}

# ラプラス近似を使用した最適化
x <- c(1,3,7,0,2,2,0,1,2,8)       # チュパカブラデータ
res_lap <- nlm(f, c(0,0), x=x)      # 最適化
res <- rbind("Guass integration"=mod_3$estimate, "Laplace approximation"=res_lap$estimate)       # ガウス積分の計算結果とラプラス近似の計算結果の比較
res[,2] <- exp(res[,2])       # 標準偏差の対数値のパラメータを元のスケールに戻す
colnames(res) <- c("mean","sd")       # パラメータの名前を設定
res       # 結果の表示

## 4 - 5 Template Model BuilderとGLMM

# ポアソン分布モデルの最適化関数
sink("pois.cpp")    # "pois.cpp"というファイルに下のcat内のものを書き込む
cat("        // " "内のものを書き込みする
// Poisson distribution

#include <TMB.hpp>      // TMBのヘッダファイル
#include <iostream>      // Cppの入出力に関するヘッダファイル

template<class Type>      // TMBのテンプレートですよという指定
Type objective_function<Type>::operator() ()
{
  // DATA //
  DATA_VECTOR(x);      // xはデータのベクトル
  
  // PARAMETER //
   PARAMETER(log_lambda);     // log_lambdaというスカラーパラメータ
   
  // PARAMETER TRANSFORMATION //
  Type lambda = exp(log_lambda);     // log_lambdaをexp変換したものをlambda（ポアソン分布の平均）とする
  
  // Main
  int N = x.size();     // xのサイズ（要素数）をNとする
  Type nll = 0.0;      // 目的関数 nll（negative log likelihoodの頭文字）の初期値を0とする
  
  for (int i=0;i<N;i++)  nll += -dpois(x(i), lambda, true);    // nllに各データの負の対数尤度をたしていく
  
  return nll;     // nllを返す
}
", fill=TRUE)     # fill=TRUEにすることで，最後に改行する
sink()      # 外部ファイルへのアクセスを終了

library(TMB)       # パッケージTMBを読み込む
compile("pois.cpp")       # 上で作られた"pois.cpp"をコンパイル
dyn.load(dynlib("pois"))       # poisファイルのDLL（ダイナミックリンクライブラリ）を作成（プログラム実行に必要）

dat <- list(x=x)       # データのリスト
pars <- list(log_lambda=0)      # パラメータの初期値
obj <- MakeADFun(dat, pars, DLL="pois")      # データとパラメータの初期値を指定して，Rで使用可能なpoisの自動微分コードを作成
mod_p <- nlminb(obj$par, obj$fn, obj$gr)      # パラメータの初期値，TMBで作られた目的関数，TMBで作られた勾配関数を指定してnlminbによって最適化（最適化の計算過程が表示されるが，表示したくなければ，MakeADFunでsilent=TRUEとする）

res <- rbind("nlm"=mod_1$estimate, "TMB"=mod_p$par)     # ポアソンモデルに対する準ニュートン法（nlm）とTMBによる最適化結果を比較
colnames(res) <- "lambda"      #　列名を指定
res     # 結果の表示

# ポアソン正規分布モデルの最適化関数
sink("pois_norm.cpp")    # "pois_norm.cpp"というファイルに下のcat内のものを書き込む
cat("        // " "内のものを書き込みする
// Poisson-Normal distribution

#include <TMB.hpp>      // TMBのヘッダファイル
#include <iostream>      // Cppの入出力に関するヘッダファイル

template<class Type>      // TMBのテンプレートですよという指定
Type objective_function<Type>::operator() ()
{
  // DATA //
  DATA_VECTOR(x);      // xはデータのベクトル
  
  // PARAMETER //
  PARAMETER(mu);      // 正規分布の平均パラメータ
  PARAMETER(log_sigma);      // 正規分布の標準偏差の対数のパラメータ
  PARAMETER_VECTOR(z);      // ランダム効果
  
  // PARAMETER TRANSFORMATION //
  Type sigma = exp(log_sigma);        // 標準偏差の対数を指数変換して標準偏差に戻す
  
  // Main
  int N = x.size();       // データのサイズ
  vector<Type> lambda(N);      // ポアソン分布の平均はデータのサイズと同じN個
  Type nll=0.0;       // 負の対数尤度（初期値=0）
    
  for (int i=0;i<N;i++){
    nll += -dnorm(z(i), mu, sigma, true);       // ランダム効果の対数尤度（正規分布）
    lambda(i) = exp(z(i));     // ポアソン分布の平均はランダム効果を指数変換したもの
    nll += -dpois(x(i), lambda(i), true);       // 観測データに対するポアソン分布の対数尤度
  }
  
  return nll;      // 負の対数尤度を出力
}
", fill=TRUE)      # 最後を改行
sink()       # 外部ファイルへのアクセスを切断

compile("pois_norm.cpp")        # ポアソン正規分布モデルのTMBファイルをコンパイル
dyn.load(dynlib("pois_norm"))       # pois_normのDLLを作成

dat <- list(x=x)      # データのリスト
pars <- list(mu=0, log_sigma=0, z=rep(0,length(x)))      # パラメータの初期値
obj <- MakeADFun(dat, pars, random="z", DLL="pois_norm")         # Rで使用可能なpois_normの自動微分コードを作成．random="z"でzをランダム効果に指定
mod_pn <- nlminb(obj$par, obj$fn, obj$gr)      # nlminbによって最適化

res <- rbind("Guass integration"=mod_3$estimate, "Laplace approximation"=mod_pn$par)       # ガウス積分を使用した結果とラプラス近似の結果を比較
res[,2] <- exp(res[,2])       # 標準偏差の対数のパラメータを標準偏差に変換
colnames(res) <- c("mean","sd")       # パラメータの名前を指定
res        # 結果を表示

library(glmmTMB)       # パッケージglmmTMBを読み込み
dat <- data.frame(x=x, n=1:length(x))        # データを設定
( mod_pn1 <- glmmTMB(x~(1|n), data=dat, family=poisson()) )      # ポアソン正規モデルを実行

mod_p1 <- nlm(mod, rep(0, length(x)), x=x, model="poisson")       # ポアソンモデルの平均をデータごとに異なるとして推定（データ1つでパラメータ1つを推定して，過剰適合になっている）
plot(x, xlab="Iteration")      # データxをプロット
points(exp(mod_p1$estimate), col=gray(0.5), pch=16)      # データごとに平均が異なるとしたポアソンモデルの平均をプロット
parms <- mod_pn1$fit$parfull       # ポアソン正規モデルのパラメータを抽出
points(exp(parms[names(parms) %in% "b"]), col="blue", pch=18)       # ランダム効果だけを抽出
abline(h=exp(parms["beta"]), lty=2)      # ポアソン正規の平均パラメータに線を引く
legend("top",c("Poissson","Poisson-Normal"), pch=c(16,18), col=c(gray(0.5),"blue"), cex=1.2)      # データごとに平均が異なるとしたポアソンモデルに対してポアソン正規モデルはshrinkageをしていることを示すプロット

## 4 - 6 ゼロ過多モデル

library(pscl)      # パッケージpsclを読み込み
data(bioChemists)       # bioChemistsデータを読み込み
dat <- bioChemists       # datにbioChemistsデータをコピー
barplot(table(dat$art))       # 論文数の内訳をプロット

summary(dat)      # bioChemsitsデータの要約を表示

mod_p <- glmmTMB(art ~ fem+mar+kid5+phd+ment, family=poisson, data=dat)     # ポアソン分布
mod_nb <- glmmTMB(art ~ fem+mar+kid5+phd+ment, family=nbinom2, data=dat)     # 負の二項分布
mod_zip <- glmmTMB(art ~ fem+mar+kid5+phd+ment, zi= ~fem+mar+kid5+phd+ment, family=poisson, data=dat)     # ゼロ過多ポアソン分布
mod_zinb <- glmmTMB(art ~ fem+mar+kid5+phd+ment, zi= ~fem+mar+kid5+phd+ment, family=nbinom2, data=dat)     # ゼロ過多負の二項分布
AIC(mod_p, mod_nb, mod_zip, mod_zinb)     # AICの比較

## 4 - 7 正則化

library(MASS)      # MASSパッケージの読み込み
data(cats)       # catsデータの読み込み
dat <- cats       # catsデータをdatにコピー
set.seed(1)      # 乱数発生のseed設定
dat$Bwt_s <- dat$Bwt + rnorm(nrow(dat),0,0.0001)      # 体重量に小さなノイズを付与
dat2 <- data.frame(y=log(dat$Hwt), x1=log(dat$Bwt), x2=log(dat$Bwt_s))        # ノイズを付与した体重量を持つデータを作成
col_mean <- apply(dat2, 2, mean)     # 各変数（列方向）の平均
col_sd <- apply(dat2, 2, sd)    #　列方向の標準偏差の計算
dat2 <- sweep(sweep(dat2,2,col_mean,FUN="-"),2,col_sd,FUN="/")    # すべての変数を平均0，標準偏差1に基準化
res <- lm(y~x1+x2, data=dat2)        # x1とx2を独立変数とした重回帰（x1とx2は非常によく似ているので多重共線性の問題が起こる）
summary(res)$coef      # 回帰係数を表示（回帰係数が大きくなり，それらの係数の標準誤差も大きくなる）

cov2cor(vcov(res))      # 回帰係数の相関係数（x1とx2の回帰係数の相関は-1）

plot(dat2$y, predict(res), xlab="Observed", ylab="Predicted")       # 観測値に対する（多重共線性を持つ）回帰モデルから得られた予測値のプロット
legend("topleft",paste0("Correlation = ", round(cor(dat2$y, predict(res)),3)))      # 凡例の設定

new_dat2 <- data.frame(x1=(log(3)-col_mean[2])/col_sd[2], x2=(log(3.1)-col_mean[3])/col_sd[3])         # x1の新しい測定値が3で，x2が3.1だとしたとき
pred_lm <- as.numeric(predict(res, newdata=new_dat2))     # 心臓重量対数値の予測値
exp(pred_lm)       # 指数変換でもとに戻す（すごくでかい値になる）
quantile(dat$Hwt, probs=c(0.01,0.99))     # 元データの心臓重量の1%点と99%点

Y <- log(dat$Hwt)       # 心臓重量の対数値
X <- model.matrix(res)       # 説明変数の行列
np <- length(res$coefficients)       # 係数の個数
E_mat <- diag(np)       # np*npの対角行列
E_mat[1,1] <- 0       #  切片をペナルティから除去するため
lambda <- c(0,10^seq(-2, 1, length = 199))      # リッジペナルティの大きさ
plot(lambda, sapply(lambda, function(k) det(t(X)%*%X+k*E_mat)), xlab="lambda", ylab="Determinant", type="l", col="blue", log="y")      # リッジペナルティに対してt(X)%*%X+lambda*E_matの行列式をプロット

beta_est <- function(lambda,Y,X) solve(t(X)%*%X+lambda*E_mat)%*%t(X)%*%Y      # リッジ回帰推定値
CV <- numeric(length(lambda))       # cross validation結果の入れ物
for (k in 1:length(lambda)){
  for (i in 1:length(Y)){
    CV[k] <- CV[k] + (Y[i]-sum(beta_est(lambda[k], Y[-i], X[-i,])*X[i,]))^2     # leave-one-out cross validation
  }
}
plot(lambda, CV)       # lambdaに対してCVの値をプロット
abline(v=lambda[which.min(CV)], col="blue", lty=2)     # loocvが最小になるlambdaに線を引く

exp(sum(beta_est(lambda[which.min(CV)],Y,X)*c(1,a
s.numeric(new_dat2))))     # リッジ回帰によるnew_dat2に対する予測値
quantile(dat$Hwt, probs=c(0.01,0.99))     # 元データの心臓重量の1%点と99%点（リッジ推定値はこの区間内に入っている）

library(glmnet)      # glmnetパッケージを読み込む
ridge_mod <- glmnet(X[,-1], Y, alpha = 0, lambda = lambda)      # 切片を除く説明変数行列と応答変数を指定．alpha=0はridge回帰となる
cv_ridge <- cv.glmnet(X, Y, alpha=0)      # cross validationを実行
bestcv_ridge <- cv_ridge$lambda.min       # cross validation errorを最小にするlambdaを特定
coef_ridge <- predict(ridge_mod, s=bestcv_ridge, type="coefficients")        # best ridge回帰モデルの回帰係数
pred_ridge <- predict(ridge_mod, s=bestcv_ridge, newx=as.matrix(new_dat2))        # best ridge回帰モデルの予測結果

lasso_mod <- glmnet(X[,-1], Y, alpha = 1, lambda = lambda)      # 切片を除く説明変数行列と応答変数を指定．alpha=1はlasso回帰となる
cv_lasso <- cv.glmnet(X, Y, alpha=1)      # cross validationを実行
bestcv_lasso <- cv_lasso$lambda.min       # cross validation errorを最小にするlambdaを特定
coef_lasso <- predict(lasso_mod, s=bestcv_lasso, type="coefficients")        # best lasso回帰モデルの回帰係数
pred_lasso <- predict(lasso_mod, s=bestcv_lasso, newx=as.matrix(new_dat2))        # best lasso回帰モデルの予測結果

betas <- cbind(res$coefficients, coef_ridge, coef_lasso)       # 制約なしの線形回帰，リッジ回帰，ラッソ回帰の回帰係数を並べて比較
preds <- exp(c(pred_lm, pred_ridge, pred_lasso))       # 制約なしの線形回帰，リッジ回帰，ラッソ回帰の予測値を指数変換したものを並べて比較
colnames(betas) <- names(preds) <- c("lm","ridge", "lasso")      # 列名を指定
betas       # 回帰係数の比較
preds       # 予測結果の比較
